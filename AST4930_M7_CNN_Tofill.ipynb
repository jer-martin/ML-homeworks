{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolution -- basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "# np.repeat: https://numpy.org/doc/stable/reference/generated/numpy.repeat.html\n",
    "sig = np.repeat([0., 1., 0.], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = signal.windows.hann(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(kernel)\n",
    "plt.gcf().set_size_inches(8, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = signal.convolve(sig, kernel, mode='same') / sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_orig, ax_win, ax_filt) = plt.subplots(3, 1, sharex=True)\n",
    "\n",
    "ax_orig.plot(sig)\n",
    "ax_orig.set_title('Original signal')\n",
    "ax_orig.margins(0, 0.1)\n",
    "\n",
    "ax_win.plot(kernel)\n",
    "ax_win.set_title('Kernel = filter response')\n",
    "ax_win.margins(0, 0.1)\n",
    "\n",
    "ax_filt.plot(convolved)\n",
    "ax_filt.set_title('Convolved signal')\n",
    "ax_filt.margins(0, 0.1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.gcf().set_size_inches(8, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: \n",
    "\n",
    "* Vary the size of the kernel (e.g., 10, 50, 100) and see how the convolved signal changes.\n",
    "\n",
    "* Change the kernel to exponential and flattop (while fixing the kernel size at 50) and see how the convolved signal changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolution in 2D\n",
    "\n",
    "This is exactly what convolutional neural networks use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal, misc\n",
    "\n",
    "img = misc.ascent()\n",
    "#img = img[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "help(misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "kernel = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(kernel, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This vertical filter helps to detect edges in the image which cut perpendicularly through the horizontal axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "img_conv = signal.convolve2d(img, kernel)\n",
    "plt.imshow(np.abs(img_conv),cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kernel = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(kernel, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This horizontal filter helps to detect edges in the image which cut horizontally through the vertical axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "img_conv = signal.convolve2d(img, kernel)\n",
    "plt.imshow(np.abs(img_conv),cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Convolve the image with the following kernels. What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "kernel = np.array([[-3,5,5],[-3,0,5],[-3,-3,-3]])\n",
    "\n",
    "kernel = np.array([[-3,-3,-3],[-3,0,5],[-3,5,5]])\n",
    "\n",
    "kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "\n",
    "kernel = np.outer(signal.windows.gaussian(50, 10), signal.windows.gaussian(50, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#NW kernel\n",
    "kernel = np.array([[-3,5,5],[-3,0,5],[-3,-3,-3]])\n",
    "plt.imshow(kernel, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#NE\n",
    "kernel = np.array([[-3,-3,-3],[-3,0,5],[-3,5,5]])\n",
    "plt.imshow(kernel, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Laplacian filter\n",
    "kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "plt.imshow(kernel, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Gaussian filter (smoothing)\n",
    "kernel = np.outer(signal.windows.gaussian(50, 10), signal.windows.gaussian(50, 10))\n",
    "plt.imshow(kernel, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exercise: Choose any picture you have on your laptop and convolve it with kernels above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# load the image\n",
    "image = Image.open('your file name/path goes here')\n",
    "\n",
    "# make the image as a numpy array\n",
    "img = np.asarray(image)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')\n",
    "plt.gcf().set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What kind of filters do CNNs use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# load VGG16 model\n",
    "model = VGG16()\n",
    "\n",
    "# retrieve weights from the second hidden layer\n",
    "filters, biases = model.layers[1].get_weights()\n",
    "\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "\n",
    "fig, ax = plt.subplots(8, 8, figsize=(10, 10))\n",
    "\n",
    "for ax, f in zip(ax.flat, filters.T):\n",
    "    ax.set(xticks=[], yticks=[])\n",
    "    ax.imshow(f[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
