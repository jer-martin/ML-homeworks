{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AST 4930 Module 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = iris.target\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_scaled = StandardScaler().fit(X_train).transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit(X_train).transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build our first neural network. We will use sklearn's MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100,100),activation=\"relu\",\n",
    "                      max_iter=1000,random_state=1,verbose=1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred=model.predict(X_test_scaled)\n",
    "print(model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, model.predict(X_test_scaled), labels=model.classes_)\n",
    "\n",
    "fig=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "fig.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are weights.\n",
    "\n",
    "print(model.coefs_[0].shape, model.coefs_[1].shape, model.coefs_[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.coefs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are weights for the bias term.\n",
    "\n",
    "print(model.intercepts_[0].shape, model.intercepts_[1].shape, model.intercepts_[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercepts_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_curve_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Training Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('mlp', MLPClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(75,50,25), (150,100,50), (300,200,100)],\n",
    "    'mlp__max_iter': [1000, 1500, 2000],\n",
    "    'mlp__solver': ['sgd', 'adam'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, return_train_score=True, cv=5, n_jobs=1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best model: {}\".format(grid_search.best_estimator_))\n",
    "print(\"Test score: {:.2f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('iris_model.pkl','wb') as f:\n",
    "    pickle.dump(grid_search.best_estimator_,f)\n",
    "\n",
    "# load\n",
    "with open('iris_model.pkl', 'rb') as f:\n",
    "    model_best = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_best.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of sklearn's MLP classifier, we can use Keras implemented onto Tensorflow. You will have to choose a Tensorflow kernel on hipergator.\n",
    "\n",
    "\n",
    "Keras: https://keras.io/\n",
    "\n",
    "Tensorflow: https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "# Initialize a model.\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add the input layer and specifying its shape.\n",
    "model.add(keras.layers.Input(shape=X_train.shape[1]))\n",
    "\n",
    "# Add the first hidden layer with 100 neurons and the ReLU activation function.\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Add the second hidden layer with 100 neurons and the ReLU activation function.\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "# softmax normalizes the output to a probability distribution\n",
    "model.add(keras.layers.Dense(np.unique(y).shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the \"architecture\" of our neural network. Note that the input layer does not show up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use the following syntax instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu',),\n",
    "    keras.layers.Dense(np.unique(y).shape[0], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the \"architecture\" of our neural network. Note that the input layer does not show up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also have a look at the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we need to \"compile\" the model before we fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful links\n",
    "\n",
    "Loss functions: https://keras.io/api/losses/ \n",
    "\n",
    "Optimizers: https://keras.io/api/optimizers/ \n",
    "\n",
    "Metrics: https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are ready to train the neural network. Let's start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.9130\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1756 - val_accuracy: 0.9130\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1700 - val_accuracy: 0.9130\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1892 - val_accuracy: 0.9130\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2018 - val_accuracy: 0.9130\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2161 - val_accuracy: 0.9130\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2039 - val_accuracy: 0.9130\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1974 - val_accuracy: 0.9130\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1856 - val_accuracy: 0.9130\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1833 - val_accuracy: 0.9130\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1943 - val_accuracy: 0.9130\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.9130\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2111 - val_accuracy: 0.9130\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.9130\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1821 - val_accuracy: 0.9130\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1964 - val_accuracy: 0.9130\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.9130\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2108 - val_accuracy: 0.9130\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.9130\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2016 - val_accuracy: 0.9130\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1972 - val_accuracy: 0.9130\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2169 - val_accuracy: 0.9130\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.9130\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2169 - val_accuracy: 0.9130\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.9130\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.9130\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2215 - val_accuracy: 0.9130\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.9130\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.9130\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2223 - val_accuracy: 0.9130\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2079 - val_accuracy: 0.9130\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2019 - val_accuracy: 0.9130\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2239 - val_accuracy: 0.9130\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2394 - val_accuracy: 0.9130\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.9130\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.9130\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2181 - val_accuracy: 0.9130\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2531 - val_accuracy: 0.9130\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2624 - val_accuracy: 0.9130\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2481 - val_accuracy: 0.9130\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.9130\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.9130\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.9130\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.9130\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2425 - val_accuracy: 0.9130\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2430 - val_accuracy: 0.9130\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2528 - val_accuracy: 0.9130\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.9130\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2167 - val_accuracy: 0.9130\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.9130\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.9130\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2603 - val_accuracy: 0.9130\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.9130\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.9130\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.9130\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2270 - val_accuracy: 0.9130\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2414 - val_accuracy: 0.9130\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2497 - val_accuracy: 0.9130\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2462 - val_accuracy: 0.9130\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.9130\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2357 - val_accuracy: 0.9130\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.9130\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2539 - val_accuracy: 0.9130\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.9130\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.9130\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.9130\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2583 - val_accuracy: 0.9130\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2395 - val_accuracy: 0.9130\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2327 - val_accuracy: 0.9130\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.9130\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.9130\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.9130\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2596 - val_accuracy: 0.9130\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.9130\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2545 - val_accuracy: 0.9130\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2630 - val_accuracy: 0.9130\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.9130\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2707 - val_accuracy: 0.9130\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2590 - val_accuracy: 0.9130\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2521 - val_accuracy: 0.9130\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.9130\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 0.9130\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2837 - val_accuracy: 0.9130\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2859 - val_accuracy: 0.9130\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.9130\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2412 - val_accuracy: 0.9130\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.9130\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.9130\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.9130\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3082 - val_accuracy: 0.9130\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3055 - val_accuracy: 0.9130\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2722 - val_accuracy: 0.9130\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.9130\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.9130\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2760 - val_accuracy: 0.9130\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2922 - val_accuracy: 0.9130\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2767 - val_accuracy: 0.9130\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2816 - val_accuracy: 0.9130\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.9130\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2795 - val_accuracy: 0.9130\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.9130\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.9130\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2981 - val_accuracy: 0.9130\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3013 - val_accuracy: 0.9130\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.9130\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2806 - val_accuracy: 0.9130\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2787 - val_accuracy: 0.9130\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.9130\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.9130\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3218 - val_accuracy: 0.9130\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.9130\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2866 - val_accuracy: 0.9130\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2945 - val_accuracy: 0.9130\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3040 - val_accuracy: 0.9130\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3018 - val_accuracy: 0.9130\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.9130\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.9130\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.9130\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3012 - val_accuracy: 0.9130\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2958 - val_accuracy: 0.9130\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.9130\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3246 - val_accuracy: 0.9130\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3184 - val_accuracy: 0.9130\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.9130\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.9130\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3007 - val_accuracy: 0.9130\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3128 - val_accuracy: 0.9130\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.9130\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2989 - val_accuracy: 0.9130\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3079 - val_accuracy: 0.9130\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3247 - val_accuracy: 0.9130\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3458 - val_accuracy: 0.9130\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3203 - val_accuracy: 0.9130\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3100 - val_accuracy: 0.9130\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.9130\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2956 - val_accuracy: 0.9130\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3240 - val_accuracy: 0.9130\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3242 - val_accuracy: 0.9130\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.9130\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3256 - val_accuracy: 0.9130\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3225 - val_accuracy: 0.9130\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3140 - val_accuracy: 0.9130\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3287 - val_accuracy: 0.9130\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.9130\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.9130\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3385 - val_accuracy: 0.9130\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.9130\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.9130\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3308 - val_accuracy: 0.9130\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3318 - val_accuracy: 0.9130\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.9130\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3336 - val_accuracy: 0.9130\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.9130\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3470 - val_accuracy: 0.9130\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3399 - val_accuracy: 0.9130\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.9130\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.9130\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3588 - val_accuracy: 0.9130\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3645 - val_accuracy: 0.9130\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3622 - val_accuracy: 0.9130\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.9130\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3269 - val_accuracy: 0.9130\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3165 - val_accuracy: 0.9130\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3444 - val_accuracy: 0.9130\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3680 - val_accuracy: 0.9130\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.9130\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.9130\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3522 - val_accuracy: 0.9130\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.9130\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.9130\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3600 - val_accuracy: 0.9130\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3737 - val_accuracy: 0.9130\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3595 - val_accuracy: 0.9130\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.9130\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.9130\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3809 - val_accuracy: 0.9130\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.9130\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3663 - val_accuracy: 0.9130\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3602 - val_accuracy: 0.9130\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.9130\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3560 - val_accuracy: 0.9130\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3849 - val_accuracy: 0.9130\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4129 - val_accuracy: 0.9130\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4043 - val_accuracy: 0.9130\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3950 - val_accuracy: 0.9130\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3523 - val_accuracy: 0.9130\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3449 - val_accuracy: 0.9130\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3464 - val_accuracy: 0.9130\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3890 - val_accuracy: 0.9130\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4096 - val_accuracy: 0.9130\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.9130\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.9130\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3709 - val_accuracy: 0.9130\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.9130\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3715 - val_accuracy: 0.9130\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3740 - val_accuracy: 0.9130\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3879 - val_accuracy: 0.9130\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3887 - val_accuracy: 0.9130\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3998 - val_accuracy: 0.9130\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.9130\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3790 - val_accuracy: 0.9130\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3766 - val_accuracy: 0.9130\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.9130\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3867 - val_accuracy: 0.9130\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.9130\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3982 - val_accuracy: 0.9130\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4192 - val_accuracy: 0.9130\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4011 - val_accuracy: 0.9130\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3897 - val_accuracy: 0.9130\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.9130\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.9130\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4065 - val_accuracy: 0.9130\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4144 - val_accuracy: 0.9130\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4076 - val_accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "# history will record the loss, accuracy, etc. \n",
    "# validation_split will split the training dataset into training + validation datasets. \n",
    "history = model.fit(X_train_scaled, y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that in each epoch, there are 3 mini batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train.shape[0]*0.8)/32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's evlauate the model using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how loss and validation loss evolved over epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'],'.-', label='loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how accuracy and validation accuracy evolved over epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The default monitor is \"val_loss\"\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu',),\n",
    "    keras.layers.Dense(np.unique(y).shape[0], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'],'.-', label='loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put weights and biases of the first hidden layer in w1 and b1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1 = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can save the model and then load it as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"iris_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = keras.models.load_model(\"iris_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try a larger dataset = the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the images to 0 - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For now, let's use 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[::10]\n",
    "X_test = X_test[::10]\n",
    "\n",
    "y_train = y_train[::10]\n",
    "y_test = y_test[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Let's build a NN with two hidden layers, each having 1000 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Print out the model summary and make sure things are correctly set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model. Let's first try Stochastic Gradient Descent with learning rate of 1.0e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Train the model using 100 epochs and 20 % of the data in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Evaluate the model using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check some of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "# Display the image.\n",
    "plt.imshow(X_test[n])\n",
    "\n",
    "# Model prediction: probability for each class.\n",
    "y_prob = model.predict(np.expand_dims(X_test[n], axis=0))\n",
    "y_prob.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The evaluation score is 88%, which is decent but not very impressive. Why? Can we improve the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how loss and accuracy have evolved over the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'],'.-', label='loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.ylim(0.7,1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like the model is still underfitting. We can increase the number of epochs or learning rate, but we can try to use the \"adam\" optimizer which will monitor and adjust the learning rate as the training proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(1000, activation=\"relu\"),\n",
    "    keras.layers.Dense(1000, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how loss and accuracy have evolved over the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.epoch, history2.history['loss'],'.-', label='loss')\n",
    "plt.plot(history2.epoch, history2.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.epoch, history2.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history2.epoch, history2.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.ylim(0.9,1.01)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
